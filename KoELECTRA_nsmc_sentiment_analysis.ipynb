{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KoELECTRA_nsmc_sentiment_analysis.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"242749a618334b969deb0b29d5a33a25":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_380838cdfb864b7687d388cf98306e39","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4c46a3bd3c914446ba5589e00a26acba","IPY_MODEL_a0288adf217e43119609c30684a4a4ac"]}},"380838cdfb864b7687d388cf98306e39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4c46a3bd3c914446ba5589e00a26acba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0ee3a24612194891819bffa4913ac4da","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":467,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":467,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0b77e85581b84403b3490ae565ece582"}},"a0288adf217e43119609c30684a4a4ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a2f1e4c8dd704c25a40cb039ed4a533a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 467/467 [00:02&lt;00:00, 202B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_db500462d7a64c59994c01367c3204ad"}},"0ee3a24612194891819bffa4913ac4da":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0b77e85581b84403b3490ae565ece582":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a2f1e4c8dd704c25a40cb039ed4a533a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"db500462d7a64c59994c01367c3204ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a93ae0f80d8e466a835ca98be81d6eb1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e49ffc5f4ca04d829135805922fe57ea","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6eedeac282394d59814c43d1137a7815","IPY_MODEL_945955a86d2b4c5b9824ca77cf4729b2"]}},"e49ffc5f4ca04d829135805922fe57ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6eedeac282394d59814c43d1137a7815":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e9a01390f2a04e1c944f3be74df67539","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":263326,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":263326,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c5062fa5f4a94b8d8dd5820911d8a007"}},"945955a86d2b4c5b9824ca77cf4729b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_036d6bdda2b843788b3a0a2b6438c2e4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 263k/263k [00:01&lt;00:00, 152kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e244c9084e9b4ffbbe787c43924ecbea"}},"e9a01390f2a04e1c944f3be74df67539":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c5062fa5f4a94b8d8dd5820911d8a007":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"036d6bdda2b843788b3a0a2b6438c2e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e244c9084e9b4ffbbe787c43924ecbea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d011f3d6417a4b7f98279be43e68e051":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_80cb5f87e7174413a0160b219c7b8037","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_379c68bd59c840daa3c136f39515b913","IPY_MODEL_f77ffe79fc714cd8bda4e08fd9108378"]}},"80cb5f87e7174413a0160b219c7b8037":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"379c68bd59c840daa3c136f39515b913":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6a12d71d267746b0996667af563bd9c8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":61,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":61,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_32649e93356040ef81c62b677577fbd3"}},"f77ffe79fc714cd8bda4e08fd9108378":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7adfe61a3e1c47f293656ba0b4a84060","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 61.0/61.0 [00:00&lt;00:00, 1.13kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d8f6430fe4294eb08a3598d3cf234394"}},"6a12d71d267746b0996667af563bd9c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"32649e93356040ef81c62b677577fbd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7adfe61a3e1c47f293656ba0b4a84060":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d8f6430fe4294eb08a3598d3cf234394":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6825e01d38f642c683d9a6fa4fd8036a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f4102f82cc394f039429c7612edad900","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9996540710ea47be8b9b74fa9aba3ae7","IPY_MODEL_f34c84e0e2c147c989b1772126a7a47f"]}},"f4102f82cc394f039429c7612edad900":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9996540710ea47be8b9b74fa9aba3ae7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5d2e9f4a9851428b974ecb766c9006dd","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":451776329,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":451776329,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b1dc8c45f5cd4065b1a480ed10ae5b05"}},"f34c84e0e2c147c989b1772126a7a47f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7d5b2501b2cd42ddba344f6c16ddfd07","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 452M/452M [00:18&lt;00:00, 24.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_96b95ddbd441430087a7acfb47ead354"}},"5d2e9f4a9851428b974ecb766c9006dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b1dc8c45f5cd4065b1a480ed10ae5b05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d5b2501b2cd42ddba344f6c16ddfd07":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"96b95ddbd441430087a7acfb47ead354":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"i45d7E0L8bZ_"},"source":["<br>\n","<br>\n","\n","# **준비 사항**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"73sTVHXAc-FP","executionInfo":{"status":"ok","timestamp":1608095339429,"user_tz":-540,"elapsed":14876,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"80a6ec98-2769-43da-cf88-41907a83d69e"},"source":["from google.colab import drive\n","drive.mount('content/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at content/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WkAHQrj2Vjbl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608095370140,"user_tz":-540,"elapsed":6464,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"0b84124c-6e12-4b2a-ce43-66e3c5ea18be"},"source":["# Hugging Face의 트랜스포머 모델을 설치\n","!pip install transformers --quiet"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 1.4MB 8.7MB/s \n","\u001b[K     |████████████████████████████████| 2.9MB 24.3MB/s \n","\u001b[K     |████████████████████████████████| 890kB 35.6MB/s \n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"75dIz2fNWG8F","executionInfo":{"status":"ok","timestamp":1608095371143,"user_tz":-540,"elapsed":6556,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}}},"source":["import tensorflow as tf\n","import torch\n","\n","from transformers import AutoTokenizer, ElectraForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import numpy as np\n","import random\n","import time\n","import datetime\n","import os\n","import re"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h_U3uMySBCIV"},"source":["<br>\n","<br>\n","\n","# **데이터 로드**"]},{"cell_type":"code","metadata":{"id":"ImBtAkSyTW1r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608095377130,"user_tz":-540,"elapsed":10242,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"59b0520b-f7d4-4c55-9f28-4d11727951f4"},"source":["# 네이버 영화리뷰 감정분석 데이터 다운로드\n","!git clone https://github.com/e9t/nsmc.git"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Cloning into 'nsmc'...\n","remote: Enumerating objects: 14763, done.\u001b[K\n","remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\u001b[K\n","Receiving objects: 100% (14763/14763), 56.19 MiB | 26.94 MiB/s, done.\n","Resolving deltas: 100% (1749/1749), done.\n","Checking out files: 100% (14737/14737), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nCKSDHcXTiKn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608095377131,"user_tz":-540,"elapsed":8642,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"197fc978-e03a-467d-b443-797c34a8f129"},"source":["# 디렉토리의 파일 목록\n","os.listdir('nsmc/')"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ratings_test.txt',\n"," '.git',\n"," 'raw',\n"," 'README.md',\n"," 'synopses.json',\n"," 'code',\n"," 'ratings_train.txt',\n"," 'ratings.txt']"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"0LPEdb2tWfIU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607873248280,"user_tz":-540,"elapsed":36941,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"aab8eda1-ad1f-4dd5-d6e2-1244bc18ba93"},"source":["filepath = 'nsmc'\n","train = pd.read_table(os.path.join(filepath, 'ratings_train.txt'))\n","test = pd.read_table(os.path.join(filepath, 'ratings_test.txt'))\n","\n","print(train.shape)\n","print(test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(150000, 3)\n","(50000, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vMvYtp6dfZsX","executionInfo":{"status":"ok","timestamp":1607873251830,"user_tz":-540,"elapsed":40482,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"bdafe013-8879-402e-c30d-727a3352501f"},"source":["# 필요 패키지 다운로드\n","!pip install soynlp --quiet  # 반복 단어 축약 soynlp repeat_normalize() 모듈 활용 예정"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[?25l\r\u001b[K     |▉                               | 10kB 29.5MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20kB 36.2MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30kB 26.3MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40kB 19.6MB/s eta 0:00:01\r\u001b[K     |████                            | 51kB 16.2MB/s eta 0:00:01\r\u001b[K     |████▊                           | 61kB 18.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 71kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 81kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 92kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 102kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 112kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 122kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 133kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 143kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 153kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 163kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 174kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 184kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 194kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 204kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 215kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 225kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 235kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 245kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 256kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 266kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 276kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 286kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 296kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 307kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 317kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 327kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 337kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 348kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 358kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 368kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 378kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 389kB 14.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 399kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 409kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 419kB 14.0MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZZoxnix-xDY2"},"source":["# 훈련 데이터셋 전처리\n","train = train.dropna(how='any')  # nan 열 제거\n","train['document'] = train['document'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣!.~;^ ]', '')  # 한국어+공백 외 제거\n","train['document'].replace('', np.nan, inplace=True)  # regex에 의해 공백으로 치환된 값 nan 값으로 변경\n","train = train.dropna(how='any')  # nan 열 제거\n","\n","# 테스트 데이터셋 전처리\n","test = test.dropna(how='any')  # nan 열 제거\n","test['document'] = test['document'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣!.~;^ ]', '')  # 한국어+공백 외 제거\n","test['document'].replace('', np.nan, inplace=True)  # regex에 의해 공백으로 치환된 값 nan 값으로 변경\n","test = test.dropna(how='any')  # nan 열 제거\n","\n","# 반복 단어 축약\n","from soynlp.normalizer import repeat_normalize\n","\n","train['document'] = train['document'].apply(lambda sentence: repeat_normalize(sentence, num_repeats=2))\n","test['document'] = test['document'].apply(lambda sentence: repeat_normalize(sentence, num_repeats=2))\n","\n","# 중복 데이터 제거\n","train.drop_duplicates(subset=['document'], inplace=True)\n","test.drop_duplicates(subset=['document'], inplace=True)\n","\n","# 파일 저장\n","train.to_csv('nsmc_preprocessed_train', encoding='utf-8')\n","test.to_csv('nsmc_preprocessed_test', encoding='utf-8')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8TGkwcd3wifh","executionInfo":{"status":"ok","timestamp":1607873253997,"user_tz":-540,"elapsed":42635,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"88edc22d-9f31-45e5-9aa6-a5c6d731d409"},"source":["print(train.columns)\n","print(test.columns)\n","print(train.head())\n","print(test.head())\n","print(train.isnull().sum())\n","print(test.isnull().sum())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Index(['id', 'document', 'label'], dtype='object')\n","Index(['id', 'document', 'label'], dtype='object')\n","         id                                           document  label\n","0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n","1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n","3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n","4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n","        id                                     document  label\n","0  6270596                                          굳 ㅋ      1\n","2  8544678         뭐야 이 평점들은.... 나쁘진 않지만 점 짜리는 더더욱 아니잖아      0\n","3  6825595             지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n","4  6723715  만 아니었어도 별 다섯 개 줬을텐데.. 왜 로 나와서 제 심기를 불편하게 하죠      0\n","5  7898805                            음악이 주가 된 최고의 음악영화      1\n","id          0\n","document    0\n","label       0\n","dtype: int64\n","id          0\n","document    0\n","label       0\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8KkJZvhccRUJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607873253998,"user_tz":-540,"elapsed":42628,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"9c99dd57-e402-434c-8ba6-ba4bbe9823f9"},"source":["# BERT의 입력 형식에 맞게 변환\n","sentences = train['document'].values\n","sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","sentences[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS] 아 더빙.. 진짜 짜증나네요 목소리 [SEP]',\n"," '[CLS] 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나 [SEP]',\n"," '[CLS] 너무재밓었다그래서보는것을추천한다 [SEP]',\n"," '[CLS] 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정 [SEP]',\n"," '[CLS] 사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다 [SEP]',\n"," '[CLS] 막 걸음마 뗀 세부터 초등학교 학년생인 살용영화.ㅋㅋㅋ...별반개도 아까움. [SEP]',\n"," '[CLS] 원작의 긴장감을 제대로 살려내지못했다. [SEP]',\n"," '[CLS] 별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네 [SEP]',\n"," '[CLS] 액션이 없는데도 재미 있는 몇안되는 영화 [SEP]',\n"," '[CLS] 왜케 평점이 낮은건데 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나 [SEP]']"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"7hBblIVQcXJR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607873253998,"user_tz":-540,"elapsed":42619,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"1080dcdb-1448-4e11-f07e-9a7c0d986b77"},"source":["# 라벨 추출\n","labels = train['label'].values\n","labels"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 0, ..., 0, 1, 0])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"PwEplfDvcnZG","colab":{"base_uri":"https://localhost:8080/","height":198,"referenced_widgets":["242749a618334b969deb0b29d5a33a25","380838cdfb864b7687d388cf98306e39","4c46a3bd3c914446ba5589e00a26acba","a0288adf217e43119609c30684a4a4ac","0ee3a24612194891819bffa4913ac4da","0b77e85581b84403b3490ae565ece582","a2f1e4c8dd704c25a40cb039ed4a533a","db500462d7a64c59994c01367c3204ad","a93ae0f80d8e466a835ca98be81d6eb1","e49ffc5f4ca04d829135805922fe57ea","6eedeac282394d59814c43d1137a7815","945955a86d2b4c5b9824ca77cf4729b2","e9a01390f2a04e1c944f3be74df67539","c5062fa5f4a94b8d8dd5820911d8a007","036d6bdda2b843788b3a0a2b6438c2e4","e244c9084e9b4ffbbe787c43924ecbea","d011f3d6417a4b7f98279be43e68e051","80cb5f87e7174413a0160b219c7b8037","379c68bd59c840daa3c136f39515b913","f77ffe79fc714cd8bda4e08fd9108378","6a12d71d267746b0996667af563bd9c8","32649e93356040ef81c62b677577fbd3","7adfe61a3e1c47f293656ba0b4a84060","d8f6430fe4294eb08a3598d3cf234394"]},"executionInfo":{"status":"ok","timestamp":1607873276653,"user_tz":-540,"elapsed":65265,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"38130856-ec66-4c98-aca3-f1892b18b3c8"},"source":["# koELECTRA의 토크나이저로 문장을 토큰으로 분리\n","tokenizer = AutoTokenizer.from_pretrained('monologg/koelectra-base-v3-discriminator')\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","print(sentences[0])\n","print(tokenized_texts[0])"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"242749a618334b969deb0b29d5a33a25","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a93ae0f80d8e466a835ca98be81d6eb1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=263326.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d011f3d6417a4b7f98279be43e68e051","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=61.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","[CLS] 아 더빙.. 진짜 짜증나네요 목소리 [SEP]\n","['[CLS]', '아', '더빙', '.', '.', '진짜', '짜증', '##나', '##네', '##요', '목소리', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HquX9FwHj2os","executionInfo":{"status":"ok","timestamp":1607873276654,"user_tz":-540,"elapsed":65257,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"d3d5f622-43ee-4ad1-d5c9-6568f9b89b15"},"source":["# 문장 최대 길이 도출\n","lengths = []\n","for token in tokenized_texts:\n","    lengths.append(len(token))\n","print(max(lengths))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["142\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VJ76KiP_dLn-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607873279798,"user_tz":-540,"elapsed":68392,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"b5c174e3-1a98-47e2-ff9f-5eebe0ce7cf7"},"source":["# 입력 토큰의 최대 시퀀스 길이\n","MAX_LEN = 160\n","\n","# 토큰을 숫자 인덱스로 변환\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","print(input_ids[0])\n","\n","# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","print(input_ids[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2, 3079, 33345, 18, 18, 7082, 13215, 4065, 4116, 4150, 6933, 3]\n","[    2  3079 33345    18    18  7082 13215  4065  4116  4150  6933     3\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pKfL8SotdVaW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607873294430,"user_tz":-540,"elapsed":83016,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"5a66646c-5fd3-43a6-c743-91e0c945cb09"},"source":["# 어텐션 마스크 초기화\n","attention_masks = []\n","\n","# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","\n","print(attention_masks[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1f5Vq3-7eNKH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607873296235,"user_tz":-540,"elapsed":84812,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"f6ec2df9-7f22-4dca-ede4-0d7c01060235"},"source":["# 훈련셋과 검증셋으로 분리\n","train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n","                                                                                    labels, \n","                                                                                    random_state=2018, \n","                                                                                    test_size=0.1)\n","\n","# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n","                                                       input_ids,\n","                                                       random_state=2018, \n","                                                       test_size=0.1)\n","\n","# 데이터를 파이토치의 텐서로 변환\n","train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_inputs = torch.tensor(validation_inputs)\n","validation_labels = torch.tensor(validation_labels)\n","validation_masks = torch.tensor(validation_masks)\t\t\t\t\n","\n","print(train_inputs[0])\n","print(train_labels[0])\n","print(train_masks[0])\n","print(validation_inputs[0])\n","print(validation_labels[0])\n","print(validation_masks[0])\n","print(train_inputs.shape)  # train 데이터 개수\n","print(validation_inputs.shape)  # validation 데이터 개수"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([    2,  2128,  4221,  4007,  4639,  5427,  3249,  6913,  9182,  4086,\n","         3249,  4820,  4244,  4189,  4353,  4366,  4149,  4441,  4814,  4216,\n","         2780,  4181, 12374,  4271,  4151,  4338,  4181,  4645,  3311,  4112,\n","         7853,  5164,  4031,  4086, 14227,  4161,  4106,  6726,  4073,  4129,\n","        28942,  4279,  4034,  4216,  2780,  4181, 30604,  4956,  2024,  4031,\n","         4086, 14227,    18,    18,    18,  6844, 12916,  8002, 21357,  4151,\n","        12919,  4153,  7593, 24008,  4176,  4172,  8575,  4441,  4814,  4216,\n","         2780,  4181,  4254,  4785, 10728,  9584,  6913,  6243,  4086,  3123,\n","         4200,  4034,  3083,  4176,     3,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n","tensor(0)\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([    2, 12493,  9753,  7959,  6434,  4007,  6264,  4151,  4827,    18,\n","            3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n","tensor(0)\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","torch.Size([130672, 160])\n","torch.Size([14520, 160])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I3vlyUJuVRo5"},"source":["# 배치 사이즈\n","batch_size = 64\n","\n","# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n","# 학습시 배치 사이즈 만큼 데이터를 가져옴\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zkqUHx51dffp"},"source":["<br>\n","<br>\n","\n","# **전처리 - 테스트셋**"]},{"cell_type":"code","metadata":{"id":"xgrsNuArd4pj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607873296237,"user_tz":-540,"elapsed":84799,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"89b04ee1-733e-459e-8170-996d4c5b2f5c"},"source":["# 리뷰 문장 추출\n","sentences = test['document']\n","sentences[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0                                                   굳 ㅋ\n","2                  뭐야 이 평점들은.... 나쁘진 않지만 점 짜리는 더더욱 아니잖아\n","3                      지루하지는 않은데 완전 막장임... 돈주고 보기에는....\n","4           만 아니었어도 별 다섯 개 줬을텐데.. 왜 로 나와서 제 심기를 불편하게 하죠\n","5                                     음악이 주가 된 최고의 음악영화\n","6                                               진정한 쓰레기\n","7               마치 미국애니에서 튀어나온듯한 창의력없는 로봇디자인부터가고개를 젖게한다\n","8     갈수록 개판되가는 중국영화 유치하고 내용없음 폼잡다 끝남 말도안되는 무기에 유치한남...\n","9             이별의 아픔뒤에 찾아오는 새로운 인연의 기쁨 모든 사람이 그렇지는 않네..\n","10                                     괜찮네요오랜만포켓몬스터잼밌어요\n","Name: document, dtype: object"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"Gtz3QZt9d4pz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607873296237,"user_tz":-540,"elapsed":84791,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"ff47cc43-0bc2-4d5d-8b39-cfe8a8adf529"},"source":["# BERT의 입력 형식에 맞게 변환\n","sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","sentences[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS] 굳 ㅋ [SEP]',\n"," '[CLS] 뭐야 이 평점들은.... 나쁘진 않지만 점 짜리는 더더욱 아니잖아 [SEP]',\n"," '[CLS] 지루하지는 않은데 완전 막장임... 돈주고 보기에는.... [SEP]',\n"," '[CLS] 만 아니었어도 별 다섯 개 줬을텐데.. 왜 로 나와서 제 심기를 불편하게 하죠 [SEP]',\n"," '[CLS] 음악이 주가 된 최고의 음악영화 [SEP]',\n"," '[CLS] 진정한 쓰레기 [SEP]',\n"," '[CLS] 마치 미국애니에서 튀어나온듯한 창의력없는 로봇디자인부터가고개를 젖게한다 [SEP]',\n"," '[CLS] 갈수록 개판되가는 중국영화 유치하고 내용없음 폼잡다 끝남 말도안되는 무기에 유치한남무 아 그립다 동사서독같은 영화가 이건 류아류작이다 [SEP]',\n"," '[CLS] 이별의 아픔뒤에 찾아오는 새로운 인연의 기쁨 모든 사람이 그렇지는 않네.. [SEP]',\n"," '[CLS] 괜찮네요오랜만포켓몬스터잼밌어요 [SEP]']"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"li8oRajbd4p3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607873296238,"user_tz":-540,"elapsed":84783,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"84de2f36-3de4-4dc5-f82c-fb84ff321bb6"},"source":["# 라벨 추출\n","labels = test['label'].values\n","labels"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 0, ..., 0, 0, 0])"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"lvpQ49nEd4p6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607873305288,"user_tz":-540,"elapsed":93825,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"7f637aa2-191e-451a-8e84-e7ec6d094f72"},"source":["# koELECTRA의 토크나이저로 문장을 토큰으로 분리\n","tokenizer = AutoTokenizer.from_pretrained('monologg/koelectra-base-v3-discriminator')\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","print(sentences[0])\n","print(tokenized_texts[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[CLS] 굳 ㅋ [SEP]\n","['[CLS]', '굳', 'ㅋ', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HI9viuAvd4p_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607873305677,"user_tz":-540,"elapsed":94205,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"c1d7eb84-3e3d-4e1b-c66e-8436208fe7b0"},"source":["# 입력 토큰의 최대 시퀀스 길이\n","MAX_LEN = 160\n","\n","# 토큰을 숫자 인덱스로 변환\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","input_ids[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   2, 2104,  287,    3,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0])"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"v1NKmP0Fd4qD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607873311998,"user_tz":-540,"elapsed":100518,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"6a7026bc-ee85-4239-cc78-757c2aea517d"},"source":["# 어텐션 마스크 초기화\n","attention_masks = []\n","\n","# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","\n","print(attention_masks[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RIkaYCGbd4qG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607873311999,"user_tz":-540,"elapsed":100511,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"c68cc94b-bb5b-4a2c-8ec7-c0a9c17fb1a3"},"source":["# 데이터를 파이토치의 텐서로 변환\n","test_inputs = torch.tensor(input_ids)\n","test_labels = torch.tensor(labels)\n","test_masks = torch.tensor(attention_masks)\n","\n","print(test_inputs[0])\n","print(test_labels[0])\n","print(test_masks[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([   2, 2104,  287,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0])\n","tensor(1)\n","tensor([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7gwdYv1Ad4qK"},"source":["# 배치 사이즈\n","batch_size = 64\n","\n","# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n","# 학습시 배치 사이즈 만큼 데이터를 가져옴\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = RandomSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FBvpU-Hfgcth"},"source":["<br>\n","<br>\n","\n","# **모델 생성**"]},{"cell_type":"code","metadata":{"id":"heToD1ev0mOg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607873315436,"user_tz":-540,"elapsed":103934,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"1788b6c6-156f-4e16-b650-c976e67e3d6d"},"source":["# GPU 디바이스 이름 구함\n","device_name = tf.test.gpu_device_name()\n","\n","# GPU 디바이스 이름 검사\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f6enIxvt1FB2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607873315437,"user_tz":-540,"elapsed":103925,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"58642a09-b567-49f4-bd79-d8fa3aa89665"},"source":["# 디바이스 설정\n","if torch.cuda.is_available():    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print('No GPU available, using the CPU instead.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla V100-SXM2-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MS2MXSiLg5zC","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["6825e01d38f642c683d9a6fa4fd8036a","f4102f82cc394f039429c7612edad900","9996540710ea47be8b9b74fa9aba3ae7","f34c84e0e2c147c989b1772126a7a47f","5d2e9f4a9851428b974ecb766c9006dd","b1dc8c45f5cd4065b1a480ed10ae5b05","7d5b2501b2cd42ddba344f6c16ddfd07","96b95ddbd441430087a7acfb47ead354"]},"executionInfo":{"status":"ok","timestamp":1607873334372,"user_tz":-540,"elapsed":122845,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"8f85af2e-4201-49e1-b167-9e7c3c3e94a6"},"source":["# 분류를 위한 BERT 모델 생성\n","model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-base-v3-discriminator\", num_labels=2)\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6825e01d38f642c683d9a6fa4fd8036a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=451776329.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["ElectraForSequenceClassification(\n","  (electra): ElectraModel(\n","    (embeddings): ElectraEmbeddings(\n","      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): ElectraEncoder(\n","      (layer): ModuleList(\n","        (0): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): ElectraClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"ZIdfbLTuWmxk"},"source":["# 옵티마이저 설정\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # 학습률\n","                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n","                )\n","\n","# 에폭수\n","epochs = 10\n","\n","# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n","total_steps = len(train_dataloader) * epochs\n","\n","# 처음에 학습률을 조금씩 변화시키는 스케줄러 생성\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gzCHV_ghj7DM"},"source":["<br>\n","<br>\n","\n","# **모델 학습**"]},{"cell_type":"code","metadata":{"id":"S0-p6pPVXCRe"},"source":["# 정확도 계산 함수\n","def flat_accuracy(preds, labels):\n","    \n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FJXISnJzCdLM"},"source":["# 시간 표시 함수\n","def format_time(elapsed):\n","\n","    # 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # hh:mm:ss으로 형태 변경\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"muU2kS2GCh4y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607884530343,"user_tz":-540,"elapsed":11318784,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"5b64b7ba-96e9-44f6-da02-5aa477f7ad29"},"source":["# 재현을 위해 랜덤시드 고정\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# 그래디언트 초기화\n","model.zero_grad()\n","\n","# 에폭만큼 반복\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # 시작 시간 설정\n","    t0 = time.time()\n","\n","    # 로스 초기화\n","    total_loss = 0\n","\n","    # 훈련모드로 변경\n","    model.train()\n","        \n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for step, batch in enumerate(train_dataloader):\n","        # 경과 정보 표시\n","        if step % 500 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # Forward 수행                \n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask, \n","                        labels=b_labels)\n","        \n","        # 로스 구함\n","        loss = outputs[0]\n","\n","        # 총 로스 계산\n","        total_loss += loss.item()\n","\n","        # Backward 수행으로 그래디언트 계산\n","        loss.backward()\n","\n","        # 그래디언트 클리핑\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # 그래디언트를 통해 가중치 파라미터 업데이트\n","        optimizer.step()\n","\n","        # 스케줄러로 학습률 감소\n","        scheduler.step()\n","\n","        # 그래디언트 초기화\n","        model.zero_grad()\n","\n","    # 평균 로스 계산\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    #시작 시간 설정\n","    t0 = time.time()\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 변수 초기화\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for batch in validation_dataloader:\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        # 그래디언트 계산 안함\n","        with torch.no_grad():     \n","            # Forward 수행\n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","        # 로스 구함\n","        logits = outputs[0]\n","\n","        # CPU로 데이터 이동\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # 출력 로짓과 라벨을 비교하여 정확도 계산\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        eval_accuracy += tmp_eval_accuracy\n","        nb_eval_steps += 1\n","\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 10 ========\n","Training...\n","  Batch   500  of  2,042.    Elapsed: 0:04:25.\n","  Batch 1,000  of  2,042.    Elapsed: 0:08:50.\n","  Batch 1,500  of  2,042.    Elapsed: 0:13:16.\n","  Batch 2,000  of  2,042.    Elapsed: 0:17:41.\n","\n","  Average training loss: 0.29\n","  Training epcoh took: 0:18:04\n","\n","Running Validation...\n","  Accuracy: 0.90\n","  Validation took: 0:00:38\n","\n","======== Epoch 2 / 10 ========\n","Training...\n","  Batch   500  of  2,042.    Elapsed: 0:04:26.\n","  Batch 1,000  of  2,042.    Elapsed: 0:08:52.\n","  Batch 1,500  of  2,042.    Elapsed: 0:13:17.\n","  Batch 2,000  of  2,042.    Elapsed: 0:17:43.\n","\n","  Average training loss: 0.21\n","  Training epcoh took: 0:18:05\n","\n","Running Validation...\n","  Accuracy: 0.90\n","  Validation took: 0:00:38\n","\n","======== Epoch 3 / 10 ========\n","Training...\n","  Batch   500  of  2,042.    Elapsed: 0:04:26.\n","  Batch 1,000  of  2,042.    Elapsed: 0:08:51.\n","  Batch 1,500  of  2,042.    Elapsed: 0:13:16.\n","  Batch 2,000  of  2,042.    Elapsed: 0:17:41.\n","\n","  Average training loss: 0.16\n","  Training epcoh took: 0:18:03\n","\n","Running Validation...\n","  Accuracy: 0.90\n","  Validation took: 0:00:38\n","\n","======== Epoch 4 / 10 ========\n","Training...\n","  Batch   500  of  2,042.    Elapsed: 0:04:25.\n","  Batch 1,000  of  2,042.    Elapsed: 0:08:49.\n","  Batch 1,500  of  2,042.    Elapsed: 0:13:14.\n","  Batch 2,000  of  2,042.    Elapsed: 0:17:38.\n","\n","  Average training loss: 0.12\n","  Training epcoh took: 0:18:00\n","\n","Running Validation...\n","  Accuracy: 0.90\n","  Validation took: 0:00:37\n","\n","======== Epoch 5 / 10 ========\n","Training...\n","  Batch   500  of  2,042.    Elapsed: 0:04:25.\n","  Batch 1,000  of  2,042.    Elapsed: 0:08:49.\n","  Batch 1,500  of  2,042.    Elapsed: 0:13:15.\n","  Batch 2,000  of  2,042.    Elapsed: 0:17:40.\n","\n","  Average training loss: 0.09\n","  Training epcoh took: 0:18:03\n","\n","Running Validation...\n","  Accuracy: 0.90\n","  Validation took: 0:00:38\n","\n","======== Epoch 6 / 10 ========\n","Training...\n","  Batch   500  of  2,042.    Elapsed: 0:04:26.\n","  Batch 1,000  of  2,042.    Elapsed: 0:08:51.\n","  Batch 1,500  of  2,042.    Elapsed: 0:13:17.\n","  Batch 2,000  of  2,042.    Elapsed: 0:17:42.\n","\n","  Average training loss: 0.07\n","  Training epcoh took: 0:18:04\n","\n","Running Validation...\n","  Accuracy: 0.90\n","  Validation took: 0:00:38\n","\n","======== Epoch 7 / 10 ========\n","Training...\n","  Batch   500  of  2,042.    Elapsed: 0:04:25.\n","  Batch 1,000  of  2,042.    Elapsed: 0:08:50.\n","  Batch 1,500  of  2,042.    Elapsed: 0:13:15.\n","  Batch 2,000  of  2,042.    Elapsed: 0:17:40.\n","\n","  Average training loss: 0.06\n","  Training epcoh took: 0:18:03\n","\n","Running Validation...\n","  Accuracy: 0.90\n","  Validation took: 0:00:38\n","\n","======== Epoch 8 / 10 ========\n","Training...\n","  Batch   500  of  2,042.    Elapsed: 0:04:25.\n","  Batch 1,000  of  2,042.    Elapsed: 0:08:50.\n","  Batch 1,500  of  2,042.    Elapsed: 0:13:15.\n","  Batch 2,000  of  2,042.    Elapsed: 0:17:40.\n","\n","  Average training loss: 0.05\n","  Training epcoh took: 0:18:02\n","\n","Running Validation...\n","  Accuracy: 0.90\n","  Validation took: 0:00:38\n","\n","======== Epoch 9 / 10 ========\n","Training...\n","  Batch   500  of  2,042.    Elapsed: 0:04:25.\n","  Batch 1,000  of  2,042.    Elapsed: 0:08:49.\n","  Batch 1,500  of  2,042.    Elapsed: 0:13:14.\n","  Batch 2,000  of  2,042.    Elapsed: 0:17:38.\n","\n","  Average training loss: 0.04\n","  Training epcoh took: 0:18:00\n","\n","Running Validation...\n","  Accuracy: 0.90\n","  Validation took: 0:00:38\n","\n","======== Epoch 10 / 10 ========\n","Training...\n","  Batch   500  of  2,042.    Elapsed: 0:04:25.\n","  Batch 1,000  of  2,042.    Elapsed: 0:08:48.\n","  Batch 1,500  of  2,042.    Elapsed: 0:13:12.\n","  Batch 2,000  of  2,042.    Elapsed: 0:17:35.\n","\n","  Average training loss: 0.04\n","  Training epcoh took: 0:17:57\n","\n","Running Validation...\n","  Accuracy: 0.90\n","  Validation took: 0:00:38\n","\n","Training complete!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6BVbl4Zjatzn"},"source":["<br>\n","<br>\n","\n","# **테스트셋 평가**"]},{"cell_type":"code","metadata":{"id":"c5KHb6RkbHdj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607884656721,"user_tz":-540,"elapsed":11445151,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"60e06174-2f7b-43b3-fd4a-99e4890ae704"},"source":["#시작 시간 설정\n","t0 = time.time()\n","\n","# 평가모드로 변경\n","model.eval()\n","\n","# 변수 초기화\n","eval_loss, eval_accuracy = 0, 0\n","nb_eval_steps, nb_eval_examples = 0, 0\n","\n","# 데이터로더에서 배치만큼 반복하여 가져옴\n","for step, batch in enumerate(test_dataloader):\n","    # 경과 정보 표시\n","    if step % 100 == 0 and not step == 0:\n","        elapsed = format_time(time.time() - t0)\n","        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n","\n","    # 배치를 GPU에 넣음\n","    batch = tuple(t.to(device) for t in batch)\n","    \n","    # 배치에서 데이터 추출\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    # 그래디언트 계산 안함\n","    with torch.no_grad():     \n","        # Forward 수행\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","    \n","    # 로스 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    \n","    # 출력 로짓과 라벨을 비교하여 정확도 계산\n","    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","    eval_accuracy += tmp_eval_accuracy\n","    nb_eval_steps += 1\n","\n","print(\"\")\n","print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","print(\"Test took: {:}\".format(format_time(time.time() - t0)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  Batch   100  of    763.    Elapsed: 0:00:17.\n","  Batch   200  of    763.    Elapsed: 0:00:33.\n","  Batch   300  of    763.    Elapsed: 0:00:50.\n","  Batch   400  of    763.    Elapsed: 0:01:06.\n","  Batch   500  of    763.    Elapsed: 0:01:23.\n","  Batch   600  of    763.    Elapsed: 0:01:39.\n","  Batch   700  of    763.    Elapsed: 0:01:56.\n","\n","Accuracy: 0.90\n","Test took: 0:02:06\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U7SzL1IBe1Dm"},"source":["<br>\n","<br>\n","\n","# **새로운 문장 테스트**"]},{"cell_type":"code","metadata":{"id":"Tb4v_VfEfGQB"},"source":["# 입력 데이터 변환\n","def convert_input_data(sentences):\n","\n","    # BERT의 토크나이저로 문장을 토큰으로 분리\n","    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","    # 입력 토큰의 최대 시퀀스 길이\n","    MAX_LEN = 160\n","\n","    # 토큰을 숫자 인덱스로 변환\n","    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","    \n","    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","    # 어텐션 마스크 초기화\n","    attention_masks = []\n","\n","    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","    for seq in input_ids:\n","        seq_mask = [float(i>0) for i in seq]\n","        attention_masks.append(seq_mask)\n","\n","    # 데이터를 파이토치의 텐서로 변환\n","    inputs = torch.tensor(input_ids)\n","    masks = torch.tensor(attention_masks)\n","\n","    return inputs, masks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C12NL1Fvgv4E"},"source":["# 문장 테스트\n","def test_sentences(sentences):\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 문장을 입력 데이터로 변환\n","    inputs, masks = convert_input_data(sentences)\n","\n","    # 데이터를 GPU에 넣음\n","    b_input_ids = inputs.to(device)\n","    b_input_mask = masks.to(device)\n","            \n","    # 그래디언트 계산 안함\n","    with torch.no_grad():     \n","        # Forward 수행\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","\n","    # 로스 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","\n","    return logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQezr0tljJlM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607884656723,"user_tz":-540,"elapsed":11445131,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"6f41bb96-235e-4569-a37f-a264d089bade"},"source":["logits = test_sentences(['주연배우가 아깝다. 총체적 난국...'])\n","\n","print(logits)\n","print(np.argmax(logits))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[ 4.0907025 -4.1015425]]\n","0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-9MQ0SK0jofN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607884656724,"user_tz":-540,"elapsed":11445122,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"d852e6b8-9567-452b-f624-d3707029d141"},"source":["logits = test_sentences(['최고의 영화'])\n","\n","print(logits)\n","print(np.argmax(logits))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[ 1.7728959 -1.8146783]]\n","0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P7Zuq23cwGYw"},"source":["<br>\n","<br>\n","\n","# **모델 저장 및 로드**"]},{"cell_type":"code","metadata":{"id":"uFD4Tq4CwE2W"},"source":["torch.save(model, './gdrive/MyDrive/sentiment_analysis/koELECTRA_nsmc_10epochs.pt')  # 저장\n","# model = torch.load('./gdrive/MyDrive/sentiment_analysis/bert_nsmc.pt')  # 로드"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MYQosgM3hZ9c","executionInfo":{"status":"ok","timestamp":1607884658595,"user_tz":-540,"elapsed":11343917,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"e3448b7a-3ca8-45f5-ffc9-d4af368ee9fe"},"source":["os.listdir('./gdrive/MyDrive/sentiment_analysis')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['friends_train.json',\n"," 'friends_dev.json',\n"," 'friends_test.json',\n"," 'ko_data.csv',\n"," 'koELECTRA_nsmc_v2.pt',\n"," 'koELECTRA_nsmc_v3.pt',\n"," 'ELECTRA_friends_multi_classification.ipynb',\n"," 'koELECTRA_nsmc_v4.pt',\n"," 'sample.csv',\n"," 'en_data.csv',\n"," 'BERT_friends.pt',\n"," 'friends_sample.csv',\n"," 'koELECTRA_nsmc_v5.pt',\n"," 'nsmc_sample.csv',\n"," 'BERT_friends_sentiment_analysis.ipynb',\n"," 'KoELECTRA_nsmc_sentiment_analysis.ipynb',\n"," 'koELECTRA_nsmc_10epochs.pt']"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"MCq12RwusHRc"},"source":["## **모델 로드 후 predict**"]},{"cell_type":"code","metadata":{"id":"SW_WlT3bwO40"},"source":["model = torch.load('./gdrive/MyDrive/sentiment_analysis/koELECTRA_nsmc_10epochs.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"4Qu6paWx1dqg","executionInfo":{"status":"ok","timestamp":1607901331173,"user_tz":-540,"elapsed":66329,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"7b8bdefc-10fe-48ce-a02e-05c8dd20c106"},"source":["# kaggle 경진대회용 파일 변환\n","df = pd.read_csv('gdrive/MyDrive/sentiment_analysis/ko_data.csv', encoding='CP949')\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>정말 많이 울었던 영화입니다.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>시간 낭비예요.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>포스터를 저렇게밖에 만들지 못했던 제작자의 소심함에 침을 뱉고 싶다.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>지금 봐도 재미있는 영화!!! 코믹과 감동!!! 그리고 요리!!!</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>이걸 영화로 만드는 거야?얼마나 가는지 보자.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Id                                Sentence\n","0   0                        정말 많이 울었던 영화입니다.\n","1   1                                시간 낭비예요.\n","2   2  포스터를 저렇게밖에 만들지 못했던 제작자의 소심함에 침을 뱉고 싶다.\n","3   3    지금 봐도 재미있는 영화!!! 코믹과 감동!!! 그리고 요리!!!\n","4   4               이걸 영화로 만드는 거야?얼마나 가는지 보자."]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"Rv-vSuBi1u13"},"source":["def sentence_preprocessing(sentence):\n","    # spaced_sent = spacing(sentence)\n","    only_korean_sent = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣!.~;^ ]', '', sentence)\n","\n","    if len(only_korean_sent) == 0:\n","      pass\n","\n","    result = repeat_normalize(only_korean_sent, num_repeats=2)\n","\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ywo25MM7Usn5"},"source":["def sent2label(sentence):\n","    logits = test_sentences([sentence])\n","    label = np.argmax(logits)\n","\n","    return label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"r58zvMgm3fJd","executionInfo":{"status":"ok","timestamp":1607901627472,"user_tz":-540,"elapsed":168157,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"d9c6e055-b210-4a76-8eeb-810f14686604"},"source":["df['Predicted'] = df['Sentence'].apply(sentence_preprocessing)\n","df['Label'] = df['Predicted'].apply(sent2label)\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Sentence</th>\n","      <th>Predicted</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>정말 많이 울었던 영화입니다.</td>\n","      <td>정말 많이 울었던 영화입니다.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>시간 낭비예요.</td>\n","      <td>시간 낭비예요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>포스터를 저렇게밖에 만들지 못했던 제작자의 소심함에 침을 뱉고 싶다.</td>\n","      <td>포스터를 저렇게밖에 만들지 못했던 제작자의 소심함에 침을 뱉고 싶다.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>지금 봐도 재미있는 영화!!! 코믹과 감동!!! 그리고 요리!!!</td>\n","      <td>지금 봐도 재미있는 영화!!! 코믹과 감동!!! 그리고 요리!!!</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>이걸 영화로 만드는 거야?얼마나 가는지 보자.</td>\n","      <td>이걸 영화로 만드는 거야얼마나 가는지 보자.</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Id  ... Label\n","0   0  ...     1\n","1   1  ...     0\n","2   2  ...     0\n","3   3  ...     1\n","4   4  ...     0\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"jSU3xiVC1xj_","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1607901654860,"user_tz":-540,"elapsed":825,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"f231f5ce-58fb-4218-b8a4-603c8f7df095"},"source":["temp_df = df[['Id', 'Label']]\n","temp_df.columns = ['Id', 'Predicted']\n","temp_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Predicted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Id  Predicted\n","0   0          1\n","1   1          0\n","2   2          0\n","3   3          1\n","4   4          0"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"-xILoIcX7Ya9"},"source":["temp_df.to_csv('gdrive/MyDrive/sentiment_analysis/nsmc_sample.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"vAa23q7sk4p-","executionInfo":{"status":"ok","timestamp":1607901657702,"user_tz":-540,"elapsed":1058,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZ2VJo13lEkkqZ9s4l8PO7yaWAGHh2_Zp1BAOLTg=s64","userId":"13477748337230346832"}},"outputId":"cd8fe029-120f-4b69-b0d0-7861ef2644fe"},"source":["test_df = pd.read_csv('gdrive/MyDrive/sentiment_analysis/nsmc_sample.csv')\n","test_df.head()\n","# test_df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Predicted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Id  Predicted\n","0   0          1\n","1   1          0\n","2   2          0\n","3   3          1\n","4   4          0"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"m3nJC27INl26"},"source":[""],"execution_count":null,"outputs":[]}]}